{"cells":[{"cell_type":"markdown","metadata":{"id":"y_ata-c-E1tk"},"source":["# Food Detection Model - Faster RCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"thQr5mCxGPHf"},"outputs":[],"source":["import torch\n","import torchvision\n","import cv2\n","from torchvision.ops import box_iou\n","import matplotlib.pyplot as plt\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","import torchvision.transforms.functional as F\n","from IPython.display import display, HTML\n","import json\n","import os\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"lDtwYuFmFsDy"},"source":["## Helper Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuNqAnb7FudU"},"outputs":[],"source":["def load_model(checkpoint_path, model, optimizer, device):\n","    \"\"\"\n","    Load the model and optimizer state from a checkpoint file and ensure they are moved to the specified device.\n","    \"\"\"\n","    if os.path.isfile(checkpoint_path):\n","        # Add map_location to ensure the checkpoint is loaded to the correct device\n","        checkpoint = torch.load(checkpoint_path, map_location=device)\n","\n","        # Load the model state\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","\n","        # Load the optimizer state\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","        # Ensure optimizer's stored states are on the right device\n","        for state in optimizer.state.values():\n","            for k, v in state.items():\n","                if isinstance(v, torch.Tensor):\n","                    state[k] = v.to(device)\n","\n","        # Load other information\n","        epoch = checkpoint['epoch']\n","        print(f\"Checkpoint loaded from {checkpoint_path} at epoch {epoch + 1}\")\n","    else:\n","        print(\"No checkpoint found at specified path!\")\n","\n","    return model, optimizer, epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrndupKCF2sF"},"outputs":[],"source":["# Load label map\n","label_map_file_path = '/content/label_map_fridgeapp.json'\n","with open(label_map_file_path, 'r') as f:\n","    loaded_label_map = json.load(f)"]},{"cell_type":"markdown","metadata":{"id":"xWbX79DjE58d"},"source":["## Faster-RCNN Model Structure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imhgAq4ME43k"},"outputs":[],"source":["class CustomTwoMLPHead(nn.Module):\n","    def __init__(self, in_channels, representation_size):\n","        super(CustomTwoMLPHead, self).__init__()\n","        self.fc6 = nn.Linear(in_channels, 4096)\n","        self.fc7 = nn.Linear(4096, 2048)\n","        self.fc8 = nn.Linear(2048, representation_size)\n","\n","    def forward(self, x):\n","        x = x.flatten(start_dim=1)\n","        x = nn.functional.relu(self.fc6(x))\n","        x = nn.functional.relu(self.fc7(x))\n","        x = nn.functional.relu(self.fc8(x))\n","        return x\n","\n","class CustomFasterRCNN(torch.nn.Module):\n","    def __init__(self, num_classes = 73):\n","        super(CustomFasterRCNN, self).__init__()\n","        self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=torchvision.models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n","        in_channels = 12544\n","        representation_size = 1024\n","\n","        self.model.roi_heads.box_head = CustomTwoMLPHead(in_channels=in_channels, representation_size=representation_size)\n","\n","        in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n","        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","    def forward(self, images, targets=None):\n","        return self.model(images, targets)"]},{"cell_type":"markdown","metadata":{"id":"3undpwA_FJMC"},"source":["## List Model Structure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aef_B1FiGL41"},"outputs":[],"source":["from torchvision.ops import box_iou\n","from IPython.display import display, HTML\n","\n","class ImageObjectDetector:\n","    def __init__(self, model, label_map, device):\n","        self.model = model.to(device)\n","        self.device = device\n","        self.label_map = label_map\n","        # Inverting the label_map for reverse lookup\n","        self.reverse_label_map = {v: k for k, v in self.label_map.items()}\n","\n","    def predict_image(self, image_path):\n","        img = cv2.imread(image_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (256, 256))\n","        img_tensor = F.to_tensor(img).unsqueeze(0)\n","        img_tensor = img_tensor.to(self.device)\n","\n","        self.model.eval()\n","        with torch.no_grad():\n","            predictions = self.model(img_tensor)\n","\n","        predictions = [{k: v.to('cpu') for k, v in t.items()} for t in predictions]\n","        prediction = predictions[0]\n","\n","        return prediction\n","\n","    def draw_boxes_on_image(self, image_path, boxes, labels, scores, threshold=0.4):\n","        image = cv2.imread(image_path)\n","        image_with_boxes = cv2.resize(image, (400, 400))\n","        orig_h, orig_w, _ = image_with_boxes.shape\n","\n","        # List to store unique labels in this photo\n","        high_confidence_labels = []\n","\n","        # List to store labels with high confidence\n","        items = []\n","        # List to store labels with their probailities\n","        probabilities = []\n","        # List to store labels with their ids\n","        ids = []\n","        # Inilital Counter\n","        counter = 1\n","\n","        for box, label, score in zip(boxes, labels, scores):\n","            if score < threshold:\n","                continue\n","\n","            item_id = counter\n","            counter += 1\n","\n","            box = box.int().numpy()\n","            start_point = (int(box[0] * orig_w / 256), int(box[1] * orig_h / 256))\n","            end_point = (int(box[2] * orig_w / 256), int(box[3] * orig_h / 256))\n","\n","            cv2.rectangle(image_with_boxes, start_point, end_point, (0, 255, 0), 2)\n","\n","            label_name = self.reverse_label_map[label.item()]\n","            if label_name not in high_confidence_labels:\n","               high_confidence_labels.append(label_name)  # Add label to the list\n","\n","            label_score = f'{item_id}. {label_name}: {score.item():.2f}'\n","\n","            # Add label to the list\n","            items.append(f\"{label_name}\")\n","            # Add probability to the list\n","            probabilities.append(score.item())\n","            # Add id to the list\n","            ids.append(item_id)\n","\n","            # Calculate text size for background rectangle\n","            text_size = cv2.getTextSize(label_score, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)[0]\n","            text_bg_rect_start = (start_point[0], end_point[1] - text_size[1] - 5)\n","            text_bg_rect_end = (start_point[0] + text_size[0], end_point[1])\n","            # text_bg_rect_start = (start_point[0], start_point[1] - text_size[1] - 5)\n","            # text_bg_rect_end = (start_point[0] + text_size[0], start_point[1])\n","\n","            # Draw white background rectangle\n","            cv2.rectangle(image_with_boxes, text_bg_rect_start, text_bg_rect_end, (255, 255, 255), -1)\n","\n","            # Draw text\n","            # cv2.putText(image, label_score, (start_point[0], start_point[1] - 5),\n","            #             cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n","            cv2.putText(image_with_boxes, label_score, (start_point[0], end_point[1] - 5),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n","\n","        plt.figure(figsize=(6, 6))\n","        plt.imshow(cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB))\n","        plt.axis('off')\n","        plt.show()\n","\n","        print(\"-----------------------------------------\")\n","\n","        # Create a DataFrame to store the results\n","        results_df = pd.DataFrame({\n","            'ID': ids,\n","            'Item and Probability': items,\n","            'Probability': probabilities\n","        })\n","\n","        # Display the DataFrame\n","        display(HTML(results_df.to_html(index=False)))\n","\n","        # print(\"Unique Ingredients from this photo:\")\n","        # for i, label in enumerate(high_confidence_labels):\n","        #     # Print the label\n","        #     print(f'{i+1}. {label}')\n","\n","        # Return Unique List and Image with Boxes\n","        return high_confidence_labels, cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB)\n","\n","    def detect_and_draw_boxes(self, image_path, threshold=0.5, iou_threshold=0.75):\n","        prediction = self.predict_image(image_path)\n","        # Directly use the tensors without unnecessary conversion\n","        boxes = prediction['boxes']\n","        scores = prediction['scores']\n","        labels = prediction['labels']\n","\n","        # Sort and NMS\n","        sorted_indices = torch.argsort(scores, descending=True)\n","        boxes = boxes[sorted_indices]\n","        scores = scores[sorted_indices]\n","        labels = labels[sorted_indices]\n","\n","        # keep = torchvision.ops.nms(boxes, scores, nms_threshold)\n","\n","        # Initialize a mask to keep track of which boxes to keep\n","        keep = torch.ones_like(scores, dtype=torch.bool)\n","\n","        # Loop through the boxes\n","        for i in range(boxes.size(0)):\n","            if keep[i] == 1:\n","            # Compute IoU with all other boxes\n","              ious = torchvision.ops.box_iou(boxes[i].unsqueeze(0), boxes).squeeze(0)\n","              # Filter out boxes with IoU > 0.3\n","              keep[i+1:] = keep[i+1:] & (ious[i+1:] < iou_threshold)\n","\n","        final_boxes = boxes[keep]\n","        final_scores = scores[keep]\n","        final_labels = labels[keep]\n","\n","        return self.draw_boxes_on_image(image_path, final_boxes, final_labels, final_scores, threshold)"]},{"cell_type":"markdown","metadata":{"id":"EK1NQXsWGbNj"},"source":["## Apply Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPuXC689Gabc"},"outputs":[],"source":["# Load Best Model\n","best_checkpoint_path = '/content/checkpoint_29.pth'\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model = CustomFasterRCNN()\n","optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n","best_model, now_optimizer, best_epoch = load_model(best_checkpoint_path, model, optimizer, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MddSkgpWFItm"},"outputs":[],"source":["# Build detector\n","detector = ImageObjectDetector(model = best_model, label_map = loaded_label_map, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyRaLWEOExPE"},"outputs":[],"source":["# Set Image Path\n","test_image = '/content/test_image.png' # Import any image you want"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Mf2c35fG_s-"},"outputs":[],"source":["# Display\n","high_confidence_labels, image_with_boxes = detector.detect_and_draw_boxes(image_path = test_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iX2-ZPQ7HE4A"},"outputs":[],"source":["# Check Unique label\n","if high_confidence_labels:\n","    print(\"High confidence labels detected in the image:\")\n","    for i, label in enumerate(high_confidence_labels, start=1):\n","        print(f'{i}. {label}')\n","else:\n","    print(\"No high confidence labels detected.\")"]},{"cell_type":"code","source":["# Show Image with Boxes\n","image_with_boxes"],"metadata":{"id":"jXOiMqMGWuii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YRNP_5KpWzv0"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}